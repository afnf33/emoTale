# emo:)Tale

팀원: 김영운, 김태희, 박건우, 변자민, 신승현, 윤보현, 이성준, 장승현

# 1. 프로젝트 제목 및 개요
양재 AI 허브에서 진행한 2020 여름 AI College의 팀프로젝트

트위터 기반 한국어 자연어 다중 감성 분석 프로젝트

인공지능 자연어 처리에서 감성 분석은 제품 사용자의 후기 분석을 통한 시장 반응 조사에서부터 소셜미디어 분석을 통한 대선 결과 예측까지 사회의 거시적 트렌드를 분석해낼 수 있는 강력한 기술임에도 불구하고, 2020년 8월 현재 SST-5에 대한 감성 분류의 SOTA 모델의 정확도가 55.5일 정도로 연구 성과가 적은 분야이다. 게다가 현재까지 진행된 감성 분석 연구는 대부분 세계 공통어인 영어를 중심으로 이루어져 있고, 상대적으로 비주류 언어인 한국어에 대한 감성 분석 연구는 충분히 이루어지지 못했다. 이 마저도 대부분이 긍정-부정을 분류하는 극성 감성 분석(polarity sentiment analysis)에 그치고 있는 상황이다. 

그러나 인간의 감정은 단순히 긍정, 부정으로 분류하기에는 너무나도 넓은 스펙트럼을 가지고 있다. 이에 우리 emo:)Tale 팀은 1. 한국어 트위터 텍스트를 기반으로, 2. 글에 드러난 [기쁨, 슬픔, 공포, 분노]의 4가지 다중 감성을 분류하는 프로젝트를 진행하여 한국어 자연어처리에서 보다 세밀한 감성 분석을 가능케하고자 한다.


# 2. 프로젝트 수행 과정
 
먼저 크롤링을 통해 100,499 개의 한국어 트위터를 확보하였다. 이를 팀원끼리 분배, 레이블링을 실시하여 총 33,853개의 텍스트로 이루어진 한국어 트위터 감성 코퍼스를 구축하였다. 이후 감정 데이터 간의 양적 비대칭성 문제를 해결하고자 각 감정에 대한 키워드를 4개 씩 선정하고, 각 키워드 당 1,000개의 텍스트를 추출하여 총 16,000개의 텍스트로 이루어진 학습 코퍼스를 구축하였다. 
 
인간의 감정이라는 모호한 개념을 다루고 있기 때문에 데이터 레이블링에 명확한 기준이 필요했다. 단일 정서를 분류하는 모델을 만들 예정이기 때문에 복합정서 표현이 들어간 텍스트는 제거하였고, 텍스트 내에서 자주 반복되는 표현은 하나로 통합하였다. 트위터 문장 사이에 단어처럼 사용하는 해시태그는 그 내용을 보존하기 위해 ‘#’ 태그만 제거하였고, 한국어 분석 모델이기에 영어, 일본어 등 외국어는 제거하였다. 이외에도 너무 많은 오타가 포함된 경우, 다른 단어임에도 단어 내의 키워드 글자 중복으로 선정된 텍스트 등을 제거하였다. 이상의 기준을 바탕으로 팀원 8명이 레이블링을 진행하였다.
 
	이상의 데이터를 바탕으로 SKTBrain에서 학습시킨 한국어용 BERT 모델, KoBERT를 사용하여 모델을 구축하였다.
  
  
# 3. 프로젝트 결과
 
각 감정에 대해 1개씩 키워드를 선정하여 크롤, 레이블 한 트위터 텍스트에 대해 성능 평가를 한 결과, 공포(ㄷㄷ)를 제외한 기쁨, 분노, 슬픔에 대해서 약 95%에 달하는 높은 분류 정확도를 보였다.
 
학습된 모델을 활용할 한가지 방안으로 일기 형태의 텍스트를 입력 받아, 그 텍스트가 담고 있는 감정을 그래프 형태로 출력하는 서비스를 구현하였다. 
향후 모델의 성능 향상을 위해 중립 정서를 분류하는 알고리즘을 추가하여 단순한 정보만을 담고 있는 텍스트나 선정한 4가지 감정으로 분류하기 애매한 텍스트를 분류하는 알고리즘을 추가할 예정이다. 또한 각 감정에 대한 키워드의 종류를 늘려 더 많은 양의 데이터로 모델을 학습시킨다면 보다 높은 성능을 낼 수 있다는 것이 확인되었다. 모델 자체에 대해서도 문장 단위를 입력으로 받는 KoBERT가 아닌, 형태소 단위를 입력으로 받는 KorBERT와 comment를 전문으로 처리하는 KcBERT를 활용한다면 더 높은 분류 성능을 기대할 수 있을 것이다. 
